{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "# import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"white\", context=\"paper\")\n",
    "from cycler import cycler\n",
    "import os, sys\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import combinations\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO as _BytesIO\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.metrics import *\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "\n",
    "# import plotly\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "\n",
    "def printm(s): return display(Markdown(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configs for data fetch and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Result summary prefix\n",
    "result_summary_prefix = 'results_summary'\n",
    "\n",
    "#timestamped predictions prefix\n",
    "ts_prediction_file_prefix = 'timestamped_predictions'\n",
    "\n",
    "# For cluster centers\n",
    "NUM_CLUSTERS = 30\n",
    "\n",
    "# Ground Truth\n",
    "gt_file = f\"../../GT_marking/gt_realworld.csv\"\n",
    "\n",
    "#for fetching specific results\n",
    "fetch_time_str = \"20210810\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## config for various kinds of graphs\n",
    "\n",
    "gconfigs = {\n",
    "    'barplot': {'color': 'blue', 'linestyle': '-.', 'marker': '.', 'alpha': 0.5}\n",
    "}\n",
    "\n",
    "\n",
    "#Percentile calculations\n",
    "def perc_75(x): return np.percentile(x, 75)\n",
    "\n",
    "\n",
    "def perc_25(x): return np.percentile(x, 25)\n",
    "\n",
    "\n",
    "#Set default RC parameters\n",
    "notebook_default_rcparams = {\n",
    "    \"axes.titlesize\": 32,\n",
    "    \"axes.labelsize\": 32,\n",
    "    \"legend.fontsize\": 32,\n",
    "    \"legend.title_fontsize\": 32,\n",
    "    \"xtick.labelsize\": 32,\n",
    "    \"ytick.labelsize\": 32,\n",
    "    \"axes.grid\": True,\n",
    "    \"legend.framealpha\": 0.5,\n",
    "    \"lines.linewidth\": 5,\n",
    "    \"legend.loc\": 'upper left'\n",
    "\n",
    "}\n",
    "rcParams.update(notebook_default_rcparams)\n",
    "\n",
    "# Standardized Labels\n",
    "\n",
    "EPSILON = 2e-2\n",
    "#plotting dir\n",
    "\n",
    "\n",
    "plotting_dir = f'plots/{datetime.now().strftime(\"%Y%m%d\")}'\n",
    "if not os.path.exists(plotting_dir):\n",
    "    os.makedirs(plotting_dir)\n",
    "out_result_dir = f'results/{datetime.now().strftime(\"%Y%m%d\")}'\n",
    "if not os.path.exists(out_result_dir):\n",
    "    os.makedirs(out_result_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Collect Ground Truth from gt file for realdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 462 entries, 0 to 461\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          462 non-null    object\n",
      " 1   start_time  462 non-null    int64 \n",
      " 2   end_time    462 non-null    int64 \n",
      " 3   context     462 non-null    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 14.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1662481192</td>\n",
       "      <td>1662481208</td>\n",
       "      <td>Exercising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1662481233</td>\n",
       "      <td>1662481253</td>\n",
       "      <td>OfficeWork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1662481266</td>\n",
       "      <td>1662481279</td>\n",
       "      <td>Exercising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1662481304</td>\n",
       "      <td>1662481318</td>\n",
       "      <td>Exercising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1662481327</td>\n",
       "      <td>1662481340</td>\n",
       "      <td>Exercising</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  start_time    end_time     context\n",
       "0  p4_3  1662481192  1662481208  Exercising\n",
       "1  p4_3  1662481233  1662481253  OfficeWork\n",
       "2  p4_3  1662481266  1662481279  Exercising\n",
       "3  p4_3  1662481304  1662481318  Exercising\n",
       "4  p4_3  1662481327  1662481340  Exercising"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt = pd.read_csv(gt_file)\n",
    "df_gt.info()\n",
    "df_gt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Final combined function for evaluation given experiment results and timestamp results and gt results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Labeling contexts with ontology\n",
    "\n",
    "if True:\n",
    "    df_onto = pd.read_csv('../../ontological_models/ontology_labels_aug11.csv', names=['activities', 'contexts'])\n",
    "    df_onto['contexts'] = df_onto['contexts'].apply(lambda x: x.split(\";\"))\n",
    "    onto_dict = df_onto.set_index('activities').to_dict()['contexts']\n",
    "\n",
    "    # df_onto_pred = pd.read_csv('../../ontological_models/ontology_predictions_v2.csv')\n",
    "    # df_onto_pred['tao_prediction'] = df_onto_pred['tao_prediction'].apply(\n",
    "    #     lambda x: x.split(\";\") if not (str(x) == 'nan') else ['Unknown'])\n",
    "    # df_onto_pred = pd.read_csv('../../datasets/realworld_dataset.csv')\n",
    "    # df_onto_pred['tao_prediction'] = df_onto_pred['session_id'].apply(lambda x: ['HavingMeal'])\n",
    "    # df_onto_pred = df_onto_pred[['session_id','timestamp','tao_prediction']]\n",
    "    # df_onto_pred.columns = ['id','timestamp','tao_prediction']\n",
    "\n",
    "\n",
    "activity_rename_mapping = {\n",
    "\n",
    "    'realworld':{\n",
    "        \"coffeemachine\": \"Cooking\",\n",
    "        \"doorknock\": \"StepIn\",\n",
    "        \"dooropen\": \"StepIn\",\n",
    "        \"eating\": \"Eating\",\n",
    "        \"jumping\": \"Hiking\",\n",
    "        \"mouse\": \"TypingOffice\",\n",
    "        \"phonering\": \"OnPhone\",\n",
    "        \"running\": \"Hiking\",\n",
    "        \"sweeping\": \"VacuumHome\",\n",
    "        \"talking\": \"Talking\",\n",
    "        \"tv\": \"WatchingTv\",\n",
    "        \"typing\": \"TypingOffice\",\n",
    "        \"vacuum\": \"VacuumHome\",\n",
    "        \"writing\": \"SittingOffice\",\n",
    "    },\n",
    "    'extrasensory': {\n",
    "        'lying': 'LyingDown',\n",
    "        'sitting': 'Sitting',\n",
    "        'walking': 'Walking',\n",
    "        'running': 'Running',\n",
    "        'cycling': 'Cycling',\n",
    "        'sleeping': 'Sleeping',\n",
    "        'meeting': 'Meeting',\n",
    "        'driving': 'Driving',\n",
    "        'exercising': 'Hiking',\n",
    "        'cooking': 'Cooking',\n",
    "        'shopping': 'Shopping',\n",
    "        'drinking': 'Drinking',\n",
    "        'shower': 'Shower',\n",
    "        'cleaning': 'VacuumHome',\n",
    "        'laundry': 'VacuumHome',\n",
    "        'clean_dishes': 'VacuumHome',\n",
    "        'watching_tv': 'WatchingTv',\n",
    "        'surfing_internet': 'ReadingOffice',\n",
    "        'singing': 'Dancing',\n",
    "        'talking': 'Talking',\n",
    "        'office_work': 'TypingOffice',\n",
    "        'eating': 'Eating',\n",
    "        'toilet': 'Toilet',\n",
    "        'grooming': 'Grooming',\n",
    "        'dressing_up': 'Grooming',\n",
    "        'stairs': 'ClimbingStairs',\n",
    "        'standing': 'Standing',\n",
    "        'meeting_coworkers': 'Meeting',\n",
    "        'meeting_friends': 'Dancing',\n",
    "\n",
    "    },\n",
    "    'casas': {\n",
    "        'step_out': 'StepOut',\n",
    "        'none': 'None',\n",
    "        'toilet': 'Toilet',\n",
    "        'onphone': 'OnPhone',\n",
    "        'grooming': 'Grooming',\n",
    "        'step_in': 'StepIn',\n",
    "        'lying': 'LyingDown',\n",
    "        'drinking': 'Drinking',\n",
    "        'watching_tv': 'WatchingTv',\n",
    "        'dressing_up': 'Grooming',\n",
    "        'taking_meds': 'Eating',\n",
    "        'wakingup': 'Sleeping',\n",
    "        'reading': 'TypingOffice',\n",
    "        'cooking': 'Cooking',\n",
    "        'eating': 'Eating',\n",
    "        'shower': 'Shower',\n",
    "        'sleeping': 'Sleeping',\n",
    "        'office_work': 'SittingOffice',\n",
    "        'dishes_home': 'VacuumHome',\n",
    "        'meeting_friends': 'Dancing',\n",
    "        'exercising': 'Running',\n",
    "        'laundry_home': 'VacuumHome'\n",
    "    },\n",
    "    'tsu': {\n",
    "        \"boil_water\": \"Cooking\",\n",
    "        \"clean_with_water\": \"VacuumHome\",\n",
    "        \"cut_cook\": \"Cooking\",\n",
    "        \"cut_bread\": \"Cooking\",\n",
    "        \"drink_cold\": \"Drinking\",\n",
    "        \"drink_hot\": \"Drinking\",\n",
    "        \"dry_up\": \"VacuumHome\",\n",
    "        \"dump_in_trash\": \"VacuumHome\",\n",
    "        \"eat_food\": \"Eating\",\n",
    "        \"eat_snack\": \"Eating\",\n",
    "        \"enter\": \"StepIn\",\n",
    "        \"get_up\": \"Sleeping\",\n",
    "        \"get_water\": \"Eating\",\n",
    "        \"insert_tea_bag\": \"Drinking\",\n",
    "        \"lay_down\": \"LyingDown\",\n",
    "        \"leave\": \"StepOut\",\n",
    "        \"pour_grains\": \"Drinking\",\n",
    "        \"pour_water\": \"Drinking\",\n",
    "        \"pour_cold\": \"Drinking\",\n",
    "        \"pour_hot\": \"Drinking\",\n",
    "        \"put_in_sink\": \"VacuumHome\",\n",
    "        \"put_on_table\": \"VacuumHome\",\n",
    "        \"read\": \"ReadingOffice\",\n",
    "        \"sit_down\": \"Sitting\",\n",
    "        \"spread_jam_or_butter\": \"Eating\",\n",
    "        \"stir_cook\": \"Cooking\",\n",
    "        \"stir_drink\": \"Drinking\",\n",
    "        \"take_ham\": \"Cooking\",\n",
    "        \"take_meds\": \"Eating\",\n",
    "        \"take_off_table\": \"Eating\",\n",
    "        \"use_furniture\": \"VacuumHome\",\n",
    "        \"use_glasses\": \"Eating\",\n",
    "        \"use_pc\": \"TypingOffice\",\n",
    "        \"use_kitchen_utility\": \"VacuumHome\",\n",
    "        \"use_telephone\": \"onPhone\",\n",
    "        \"walk\": \"Walking\",\n",
    "        \"watch_tv\": \"WatchingTv\",\n",
    "        \"clean_table\": \"VacuumHome\",\n",
    "        \"write\": \"ReadingOffice\"\n",
    "    }\n",
    "}\n",
    "\n",
    "tsu_context_mapping = {\n",
    "    \"ComingIn\": [\"tsuBreakfast\"],\n",
    "    \"Commuting\": [\"tsuBreakfast\", \"tsuCook\"],\n",
    "    \"GoingOut\": [\"tsuBreakfast\"],\n",
    "    \"HavingMeal\": [\"tsuMakecoffee\", \"tsuMaketea\"],\n",
    "    \"HouseWork\": [\"tsuCleandishes\"],\n",
    "    \"PreparingMeal\": [\"tsuCook\"],\n",
    "    \"Relaxing\": [\"tsuBreakfast\"],\n",
    "}\n",
    "\n",
    "\n",
    "def label_context_v1(cluster_representation, activity_renaming, conf_activities=['sitting', 'standing', 'talking']):\n",
    "    # print(cluster_representation)\n",
    "    act_train = cluster_representation.split(\">\")\n",
    "    act_train = [xr.split(\"+\") for xr in act_train]\n",
    "\n",
    "    unique_activities = set()\n",
    "    for act_set in act_train:\n",
    "        for activity in act_set:\n",
    "            unique_activities.add(activity)\n",
    "    for conf_act in conf_activities:\n",
    "        try:\n",
    "            unique_activities.remove(conf_act)\n",
    "        except:\n",
    "            ...\n",
    "\n",
    "    if len(unique_activities) > 0:\n",
    "        # print(\"More than conf activities in the set, removing conf activities for precise context labeling\")\n",
    "        act_train = [([activity for activity in act_set if (activity not in conf_activities)]) for act_set in act_train]\n",
    "        # print(act_train)\n",
    "\n",
    "    for i in range(len(act_train)):\n",
    "        for j in range(len(act_train[i])):\n",
    "            # print(act_train,act_train[i], act_train[i][j])\n",
    "            if not act_train[i][j] == 'unknown':\n",
    "                act_train[i][j] = activity_renaming[act_train[i][j]].lower()\n",
    "            else:\n",
    "                act_train[i][j] = 'none'\n",
    "        act_train[i] = sorted(np.unique(act_train[i]).tolist())\n",
    "\n",
    "    #for sequential contexts\n",
    "    # try:\n",
    "    seq_contexts = []\n",
    "    for i in range(1, len(act_train)):\n",
    "        set1, set2 = act_train[i - 1], act_train[i]\n",
    "        for first_act in set1:\n",
    "            for sec_act in set2:\n",
    "                # print(f\"seq: {first_act},{sec_act}\")\n",
    "                if not first_act == sec_act:\n",
    "                    try:\n",
    "                        seq_ctx = onto_dict[\n",
    "                            f'{first_act}+{sec_act}']\n",
    "                        if not (seq_ctx[0] == 'Unknown'):\n",
    "                            seq_contexts += seq_ctx\n",
    "                    except:\n",
    "                        ...\n",
    "\n",
    "    # for parallel contexts\n",
    "    single_act_contexts = []\n",
    "    par_contexts = []\n",
    "    for act_set in act_train:\n",
    "        if len(act_set) == 1:\n",
    "            single_ctx = onto_dict[f\"{act_set[0]}\"]\n",
    "            if not (single_ctx[0] == 'Unknown'):\n",
    "                single_act_contexts += single_ctx\n",
    "        else:\n",
    "            for act1, act2 in combinations(act_set, 2):\n",
    "                if not act1 == act2:\n",
    "                    par_ctx = ['Unknown']\n",
    "                    try:\n",
    "                        par_ctx = onto_dict[f\"{act1}_{act2}\"]\n",
    "                    except:\n",
    "                        par_ctx = onto_dict[f\"{act2}_{act1}\"]\n",
    "                    if not (par_ctx[0] == 'Unknown'):\n",
    "                        par_contexts += par_ctx\n",
    "\n",
    "    final_context_set = None\n",
    "    if len(seq_contexts) > 0:\n",
    "        final_context_set = np.unique(seq_contexts).tolist()\n",
    "    elif len(par_contexts) > 0:\n",
    "        final_context_set = np.unique(par_contexts).tolist()\n",
    "    elif len(single_act_contexts) > 0:\n",
    "        final_context_set = np.unique(single_act_contexts).tolist()\n",
    "    else:\n",
    "        all_contexts = []\n",
    "        for act_set in act_train:\n",
    "            for activity in act_set:\n",
    "                single_ctx = onto_dict[f\"{activity}\"]\n",
    "                if not (single_ctx[0] == 'Unknown'):\n",
    "                    all_contexts += single_ctx\n",
    "        final_context_set = np.unique(all_contexts).tolist()\n",
    "\n",
    "    # tsu specific conversion\n",
    "    if dataset == 'tsu':\n",
    "        tsu_final_contexts = []\n",
    "        for context in final_context_set:\n",
    "            if context in tsu_context_mapping.keys():\n",
    "                tsu_final_contexts += tsu_context_mapping[context]\n",
    "        if len(tsu_final_contexts) > 0:\n",
    "            return np.unique(tsu_final_contexts).tolist()\n",
    "        else:\n",
    "            return ['Unknown']\n",
    "    else:\n",
    "        return final_context_set\n",
    "\n",
    "    # except:\n",
    "    #     return ['Unknown']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions for main accuracy function\n",
    "\n",
    "def get_ctx_vec(ctx_str, contexts):\n",
    "    ctx_vec = np.zeros(len(contexts))\n",
    "    for item_i in ctx_str.split(\",\"):\n",
    "        if not item_i in ['', 'Unknown']:\n",
    "            ctx_vec[contexts.index(item_i)] = 1\n",
    "    return ctx_vec\n",
    "\n",
    "def get_cluster_labels(cluster_centers, dataset, labeling_func=label_context_v1):\n",
    "    cluster_centers = [center.split(\")__\")[0].split(\"(\")[-1] for center in cluster_centers]\n",
    "    cluster_labels = [labeling_func(center, activity_rename_mapping[dataset]) for center in cluster_centers]\n",
    "    return cluster_labels\n",
    "\n",
    "def compile_ts_results_v2(ts_results, df_onto_pred, df_gt, cluster_labels):\n",
    "    #compiled final timestamped results with GT\n",
    "    compiled_ts_results_dict = dict()\n",
    "    # compiled_instance_results_dict = dict()\n",
    "    for key in ts_results.keys():\n",
    "        df_pred_id = ts_results[key]\n",
    "        df_pred_id['id'] = key\n",
    "        df_gt_id = df_gt[df_gt.id == key]\n",
    "        df_onto_pred_id = df_onto_pred[df_onto_pred.id==key]\n",
    "        df_pred_id = df_pred_id[df_pred_id.end_timestamp >= df_gt_id.start_time.min()]\n",
    "        df_pred_id = df_pred_id[df_pred_id.start_timestamp <= df_gt_id.end_time.max()]\n",
    "        if (df_gt_id.shape[0] > 0) & (df_pred_id.shape[0] > 0) & (df_onto_pred_id.shape[0] > 0):\n",
    "            # if (df_gt_id.shape[0] > 0) & (df_pred_id.shape[0] > 0):\n",
    "            print(f\"Starting on {key}\")\n",
    "            #process gt to timestamp, context format\n",
    "            gt_min_ts, gt_max_ts = df_gt_id.start_time.min(), df_gt_id.end_time.max()\n",
    "            df_gt_ts = pd.DataFrame(np.arange(gt_min_ts, gt_max_ts + 1), columns=['timestamp'])\n",
    "            df_gt_ts['gt_context'] = ''\n",
    "            df_gt_ts = df_gt_ts.set_index('timestamp')\n",
    "            for row_idx, row in df_gt_id.iterrows():\n",
    "                df_gt_ts.loc[row['start_time']:row['end_time'], 'gt_context'] = df_gt_ts.loc[\n",
    "                                                                                row['start_time']:row['end_time'],\n",
    "                                                                                'gt_context'].apply(\n",
    "                    lambda x: row['context'] if (x == '') else (x + ',' + row['context']))\n",
    "\n",
    "            #get ts based prediction\n",
    "            pred_min_ts, pred_max_ts = df_pred_id.start_timestamp.min(), df_pred_id.end_timestamp.max()\n",
    "            df_pred_ts = pd.DataFrame(np.arange(pred_min_ts, pred_max_ts + 1), columns=['timestamp'])\n",
    "            df_pred_ts['pred_context'] = None\n",
    "            df_pred_ts = df_pred_ts.set_index('timestamp')\n",
    "            for row_idx, row in df_pred_id.iterrows():\n",
    "                df_pred_ts.loc[row['start_timestamp']:row['end_timestamp'], 'pred_context'] = df_pred_ts.loc[\n",
    "                                                                                              row['start_timestamp']:\n",
    "                                                                                              row['end_timestamp'],\n",
    "                                                                                              'pred_context'].apply(\n",
    "                    lambda x: (x + cluster_labels[row['cluster_id']]) if x is not None else cluster_labels[\n",
    "                        row['cluster_id']])\n",
    "\n",
    "\n",
    "            #merge timestaped gt and predictions together for the user\n",
    "            df_compiled_results_ts_id = pd.merge(df_pred_ts.reset_index(), df_gt_ts.reset_index(), on='timestamp')\n",
    "            df_compiled_results_ts_id['id'] = key\n",
    "            df_compiled_results_ts_id = df_compiled_results_ts_id[\n",
    "                ['id', 'timestamp', 'gt_context', 'pred_context']]\n",
    "            df_compiled_results_ts_id = df_compiled_results_ts_id[~df_compiled_results_ts_id.gt_context.isnull()]\n",
    "            df_compiled_results_ts_id = df_compiled_results_ts_id[~df_compiled_results_ts_id.pred_context.isnull()]\n",
    "            df_compiled_results_ts_id = pd.merge(df_compiled_results_ts_id,df_onto_pred_id,on =['id','timestamp'],suffixes=('','_onto'))\n",
    "            df_compiled_results_ts_id['combined_context'] = df_compiled_results_ts_id.apply(lambda row: row['pred_context']+row['tao_prediction'],axis=1)\n",
    "\n",
    "            # format as a comma separated string\n",
    "            df_compiled_results_ts_id['onto_context'] = df_compiled_results_ts_id['tao_prediction'].apply(\n",
    "                lambda x: ','.join(sorted(np.unique(x).tolist())))\n",
    "            df_compiled_results_ts_id['pred_context'] = df_compiled_results_ts_id['pred_context'].apply(\n",
    "                lambda x: ','.join(sorted(np.unique(x).tolist())))\n",
    "            df_compiled_results_ts_id['combined_context'] = df_compiled_results_ts_id['combined_context'].apply(\n",
    "                lambda x: ','.join(sorted(np.unique(x).tolist())))\n",
    "\n",
    "            #remove null ground truth\n",
    "            df_compiled_results_ts_id= df_compiled_results_ts_id[~(df_compiled_results_ts_id.gt_context=='')]\n",
    "            #todo: added to deactivate ontology\n",
    "            # df_compiled_results_ts_id['onto_context'] = df_compiled_results_ts_id['pred_context']\n",
    "            # df_compiled_results_ts_id['combined_context'] = df_compiled_results_ts_id['pred_context']\n",
    "\n",
    "            compiled_ts_results_dict[key] = df_compiled_results_ts_id\n",
    "            print(f\"Processed for id {key}\")\n",
    "    return compiled_ts_results_dict\n",
    "\n",
    "\n",
    "def find_all_present_contexts(df_gt_ts):\n",
    "    '''\n",
    "\n",
    "    :param df_gt_ts:\n",
    "    :type df_gt_ts:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    '''\n",
    "    context_set = set()\n",
    "    for context in df_gt_ts['gt_context'].unique():\n",
    "        for item in context.split(\",\"):\n",
    "            context_set.add(item)\n",
    "\n",
    "    for context in df_gt_ts['pred_context'].unique():\n",
    "        for item in context.split(\",\"):\n",
    "            context_set.add(item)\n",
    "\n",
    "    context_set.remove('')\n",
    "    all_contexts = sorted(list(context_set))\n",
    "    return all_contexts\n",
    "\n",
    "def get_overall_metrics(gt_arr, pred_arr):\n",
    "\n",
    "    # calculate spot by converting it into +0.2 JC\n",
    "    gt_or_pred = np.sum(np.logical_or(gt_arr,pred_arr),axis=1)\n",
    "    gt_eq_pred = np.sum(np.logical_and(gt_arr,pred_arr),axis=1)\n",
    "    jc_samples = gt_eq_pred/gt_or_pred\n",
    "    is_spot = jc_samples>0.2\n",
    "    spot_acc = round(is_spot.sum()*100/is_spot.shape[0],2)\n",
    "    # gt_xor_pred = np.sum(np.logical_xor(gt_arr,pred_arr),axis=1)\n",
    "    # is_norm = (gt_xor_pred==0)\n",
    "    # norm_acc = round(is_norm.sum()*100/is_norm.shape[0],2)\n",
    "\n",
    "\n",
    "\n",
    "    jc_score_samples = round(jaccard_score(gt_arr, pred_arr, average='samples',zero_division=0) * 100, 2)\n",
    "    f1_acc =round(f1_score(gt_arr, pred_arr, average='weighted',zero_division=0) * 100, 2)\n",
    "    avg_prec = round(precision_score(gt_arr, pred_arr, average='weighted',zero_division=0) * 100, 2)\n",
    "    avg_recall = round(recall_score(gt_arr, pred_arr, average='weighted',zero_division=0) * 100, 2)\n",
    "    avg_f1 = round(f1_score(gt_arr, pred_arr, average='weighted',zero_division=0) * 100, 2)\n",
    "    return f1_acc, avg_prec, avg_recall, jc_score_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loop over experiments to create overarching result csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id   timestamp activity tao_prediction\n",
      "0  p10_1  1662667543  noevent      [Unknown]\n",
      "1  p10_1  1662667544  noevent      [Unknown]\n",
      "2  p10_1  1662667545  noevent      [Unknown]\n",
      "3  p10_1  1662667546  noevent      [Unknown]\n",
      "4  p10_1  1662667547  noevent      [Unknown]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p1_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw//p1_dataset_0.05_0.01_TAE/results/results_summary_20220913_101014.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p10_1\n",
      "Processed for id p10_1\n",
      "Starting on p10_2\n",
      "Processed for id p10_2\n",
      "Starting on p10_3\n",
      "Processed for id p10_3\n",
      "Starting on p10_4\n",
      "Processed for id p10_4\n",
      "Starting on p1_1\n",
      "Processed for id p1_1\n",
      "Starting on p1_2\n",
      "Processed for id p1_2\n",
      "Starting on p1_3\n",
      "Processed for id p1_3\n",
      "Starting on p1_4\n",
      "Processed for id p1_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      71.81  88.48  61.00  65.57\n",
      "temporal  72.42  69.77  78.50  66.23\n",
      "combined  73.31  68.54  82.28  65.91\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn    100.00     60.56         94.67        100.00   \n",
      "1       Exercising    100.00     93.53         94.97        100.00   \n",
      "2       HavingMeal    100.00     71.11         76.77         88.15   \n",
      "3        HouseWork    100.00     69.44         58.20         71.83   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork    100.00     70.03         86.02         84.20   \n",
      "7        PhoneCall     53.95     33.47         68.95         61.63   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00     51.40         35.65         93.46   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         94.67        100.00  \n",
      "1         94.97        100.00  \n",
      "2         76.77         88.15  \n",
      "3         65.70         98.81  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         86.02         84.20  \n",
      "7         52.25         61.63  \n",
      "8          0.00          0.00  \n",
      "9         35.65         93.46  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p1_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p3_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw//p3_dataset_0.05_0.01_TAE/results/results_summary_20220913_101153.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p3_1\n",
      "Processed for id p3_1\n",
      "Starting on p3_2\n",
      "Processed for id p3_2\n",
      "Starting on p3_3\n",
      "Processed for id p3_3\n",
      "Starting on p3_4\n",
      "Processed for id p3_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      68.16  87.32  56.48  61.28\n",
      "temporal  70.65  71.44  75.07  63.72\n",
      "combined  70.74  68.66  77.94  63.64\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn    100.00     56.41         97.50        100.00   \n",
      "1       Exercising    100.00     93.42         66.09        100.00   \n",
      "2       HavingMeal    100.00     62.50         78.89         80.68   \n",
      "3        HouseWork    100.00     65.69         46.90         77.37   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork    100.00     66.95         89.80         78.45   \n",
      "7        PhoneCall     60.23     32.32         90.74         59.76   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00     48.96         40.68        100.00   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         97.50        100.00  \n",
      "1         66.09        100.00  \n",
      "2         78.89         80.68  \n",
      "3         52.94         98.54  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         89.80         78.45  \n",
      "7         68.53         59.76  \n",
      "8          0.00          0.00  \n",
      "9         40.68        100.00  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p3_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p10_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw//p10_dataset_0.05_0.01_TAE/results/results_summary_20220913_101034.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p10_1\n",
      "Processed for id p10_1\n",
      "Starting on p10_2\n",
      "Processed for id p10_2\n",
      "Starting on p10_3\n",
      "Processed for id p10_3\n",
      "Starting on p10_4\n",
      "Processed for id p10_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      73.02  87.43  63.33  68.25\n",
      "temporal  72.58  67.91  79.22  68.86\n",
      "combined  71.42  65.52  79.22  66.71\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn    100.00     74.36        100.00         97.44   \n",
      "1       Exercising    100.00     94.32         93.62        100.00   \n",
      "2       HavingMeal    100.00     80.33         75.36         85.25   \n",
      "3        HouseWork    100.00     76.12         72.83        100.00   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork    100.00     71.15         69.48         81.73   \n",
      "7        PhoneCall     52.27     35.11         68.47         58.02   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00     50.50         52.15         84.16   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0        100.00         97.44  \n",
      "1         93.62        100.00  \n",
      "2         75.36         85.25  \n",
      "3         72.83        100.00  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         69.48         81.73  \n",
      "7         51.70         58.02  \n",
      "8          0.00          0.00  \n",
      "9         52.15         84.16  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p10_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p5_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw//p5_dataset_0.05_0.01_TAE/results/results_summary_20220913_101232.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p5_1\n",
      "Processed for id p5_1\n",
      "Starting on p5_2\n",
      "Processed for id p5_2\n",
      "Starting on p5_3\n",
      "Processed for id p5_3\n",
      "Starting on p5_4\n",
      "Processed for id p5_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      72.32  88.70  61.79  66.00\n",
      "temporal  74.16  75.12  77.02  70.33\n",
      "combined  73.11  71.30  77.26  69.11\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn    100.00     90.62         94.12        100.00   \n",
      "1       Exercising    100.00     93.41        100.00         98.90   \n",
      "2       HavingMeal    100.00     65.71         85.07         81.43   \n",
      "3        HouseWork    100.00     78.38         54.04         96.40   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork    100.00     64.24         84.56         79.86   \n",
      "7        PhoneCall     51.56     32.04         89.09         47.57   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00     54.00         55.03         82.00   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         94.12        100.00  \n",
      "1        100.00         98.90  \n",
      "2         85.07         81.43  \n",
      "3         54.04         96.40  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         84.56         79.86  \n",
      "7         57.95         49.51  \n",
      "8          0.00          0.00  \n",
      "9         55.03         82.00  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p5_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p7_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw//p7_dataset_0.05_0.01_TAE/results/results_summary_20220913_101350.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p7_1\n",
      "Processed for id p7_1\n",
      "Starting on p7_2\n",
      "Processed for id p7_2\n",
      "Starting on p7_3\n",
      "Processed for id p7_3\n",
      "Starting on p7_4\n",
      "Processed for id p7_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      71.43  88.45  60.77  65.47\n",
      "temporal  77.45  76.69  81.14  73.63\n",
      "combined  76.11  73.81  81.14  70.21\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn    100.00     70.59         94.44        100.00   \n",
      "1       Exercising    100.00     93.90        100.00        100.00   \n",
      "2       HavingMeal    100.00     65.22         82.19         86.96   \n",
      "3        HouseWork    100.00     79.28         62.71        100.00   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork    100.00     69.02         89.43         79.80   \n",
      "7        PhoneCall     53.12     27.87         88.00         72.13   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00     48.04         44.50         83.33   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         94.44        100.00  \n",
      "1        100.00        100.00  \n",
      "2         82.19         86.96  \n",
      "3         62.71        100.00  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         89.43         79.80  \n",
      "7         67.69         72.13  \n",
      "8          0.00          0.00  \n",
      "9         44.50         83.33  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p7_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p2_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw//p2_dataset_0.05_0.01_TAE/results/results_summary_20220913_101109.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p2_1\n",
      "Processed for id p2_1\n",
      "Starting on p2_2\n",
      "Processed for id p2_2\n",
      "Starting on p2_3\n",
      "Processed for id p2_3\n",
      "Starting on p2_4\n",
      "Processed for id p2_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      71.05  87.66  60.38  64.50\n",
      "temporal  68.93  68.09  75.49  60.85\n",
      "combined  69.72  65.57  79.64  61.08\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn     100.0     58.33         92.31        100.00   \n",
      "1       Exercising     100.0     92.86         65.42        100.00   \n",
      "2       HavingMeal     100.0     69.66         68.91         92.13   \n",
      "3        HouseWork     100.0     73.81         39.13         64.29   \n",
      "4       InAMeeting       0.0      0.00          0.00          0.00   \n",
      "5  MealPreparation       0.0      0.00          0.00          0.00   \n",
      "6       OfficeWork     100.0     72.36         89.05         81.57   \n",
      "7        PhoneCall      49.4     28.08         80.23         47.26   \n",
      "8    PreparingMeal       0.0      0.00          0.00          0.00   \n",
      "9         Relaxing     100.0     49.60         42.96        100.00   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         92.31        100.00  \n",
      "1         65.42        100.00  \n",
      "2         68.91         92.13  \n",
      "3         49.40         97.62  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         89.05         81.57  \n",
      "7         53.91         47.26  \n",
      "8          0.00          0.00  \n",
      "9         42.96        100.00  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p2_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p4_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw//p4_dataset_0.05_0.01_TAE/results/results_summary_20220913_115140.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p4_1\n",
      "Processed for id p4_1\n",
      "Starting on p4_2\n",
      "Processed for id p4_2\n",
      "Starting on p4_3\n",
      "Processed for id p4_3\n",
      "Starting on p4_4\n",
      "Processed for id p4_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      70.85  88.64  59.29  63.07\n",
      "temporal  71.67  71.34  76.60  67.21\n",
      "combined  71.51  68.57  78.21  66.61\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn    100.00     51.52         76.74        100.00   \n",
      "1       Exercising    100.00     91.67         89.55        100.00   \n",
      "2       HavingMeal    100.00     67.44         68.22         84.88   \n",
      "3        HouseWork    100.00     68.85         59.80        100.00   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork    100.00     65.57         88.28         72.16   \n",
      "7        PhoneCall     57.14     37.21         75.28         51.94   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00     61.16         53.78        100.00   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         76.74        100.00  \n",
      "1         89.55        100.00  \n",
      "2         68.22         84.88  \n",
      "3         59.80        100.00  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         88.89         76.65  \n",
      "7         53.60         51.94  \n",
      "8          0.00          0.00  \n",
      "9         53.78        100.00  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p4_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p6_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw//p6_dataset_0.05_0.01_TAE/results/results_summary_20220913_100806.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p6_1\n",
      "Processed for id p6_1\n",
      "Starting on p6_2\n",
      "Processed for id p6_2\n",
      "Starting on p6_3\n",
      "Processed for id p6_3\n",
      "Starting on p6_4\n",
      "Processed for id p6_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      73.19  88.63  63.03  67.36\n",
      "temporal  66.00  60.65  76.95  59.15\n",
      "combined  66.32  59.93  79.18  58.64\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn    100.00     75.76         47.83        100.00   \n",
      "1       Exercising    100.00     92.94         80.39         96.47   \n",
      "2       HavingMeal     85.71     72.73         43.31         83.33   \n",
      "3        HouseWork    100.00     80.00         46.89         81.67   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork    100.00     67.48         80.97         76.99   \n",
      "7        PhoneCall     56.06     28.68         51.88         53.49   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00     59.22         43.46        100.00   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         47.83        100.00  \n",
      "1         80.39         96.47  \n",
      "2         43.31         83.33  \n",
      "3         51.53         98.33  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         80.97         76.99  \n",
      "7         42.59         53.49  \n",
      "8          0.00          0.00  \n",
      "9         43.46        100.00  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p6_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "gt_cache_dir = \"../../cache/sep12_rw/\"\n",
    "experiment_dirs = glob.glob(f'{gt_cache_dir}/*')\n",
    "df_gt_onto_pred = pd.read_csv(\"../../ontological_models/real_world_ontology_predictions.csv\")\n",
    "# df_gt_onto_pred['tao_prediction'] = df_gt_onto_pred['tao_prediction'].apply(lambda x: x.replace('noevent','Unknown'))\n",
    "df_gt_onto_pred['tao_prediction'] = df_gt_onto_pred['tao_prediction'].apply(\n",
    "    lambda x: x.split(\";\") if not (str(x) == 'nan') else ['Unknown'])\n",
    "df_gt_onto_pred['tao_prediction'] = df_gt_onto_pred['tao_prediction'].apply(\n",
    "    lambda x: ['Unknown'] if (x[0]=='noevent') else x)\n",
    "df_gt_onto_pred = df_gt_onto_pred.rename(columns={'session_id':'id'})\n",
    "print(df_gt_onto_pred.head())\n",
    "\n",
    "df_metrics =None\n",
    "for experiment_dir in experiment_dirs:\n",
    "    experiment = experiment_dir.split(\"/\")[-1]\n",
    "    experiment_out_dir = f'{out_result_dir}/{experiment}'\n",
    "    if not os.path.exists(experiment_out_dir):\n",
    "        os.makedirs(experiment_out_dir)\n",
    "\n",
    "    printm(f\"## --------------------------- Started Experiment: {experiment} ----------------------------\")\n",
    "    # Compile results into ts dict\n",
    "    printm(\"### fetch results for experiment\")\n",
    "    if True:\n",
    "        result_file = sorted(glob.glob(f\"{gt_cache_dir}/{experiment}/results/{result_summary_prefix}*.json\"))[-1]\n",
    "        ts_file = sorted(glob.glob(f\"{gt_cache_dir}/{experiment}/results/{ts_prediction_file_prefix}*.pb\"))[-1]\n",
    "        print(result_file)\n",
    "        exp_results = json.load(open(result_file, 'r'))\n",
    "        ts_results = pickle.load(open(ts_file, 'rb'))\n",
    "        cluster_centers = exp_results['direct_labels']\n",
    "        dataset = exp_results['run_config']['dataset']\n",
    "\n",
    "    # Filter out only test instances from ts_results\n",
    "    zero_shape_ids = []\n",
    "    for id in ts_results.keys():\n",
    "        # print(f\"id:{id}:{ts_results[id].shape}\")\n",
    "        ts_results[id] = ts_results[id][ts_results[id].isTrain==False]\n",
    "        # print(f\"id:{id}:{ts_results[id].shape}\")\n",
    "        if ts_results[id].shape[0]==0:\n",
    "            zero_shape_ids.append(id)\n",
    "    for id in zero_shape_ids:\n",
    "        del ts_results[id]\n",
    "\n",
    "\n",
    "    printm(\"### get cluster labels and best representation accuracy\")\n",
    "    if True:\n",
    "        direct_cluster_centers = exp_results['direct_labels']\n",
    "        direct_cluster_labels = get_cluster_labels(direct_cluster_centers, dataset, label_context_v1)\n",
    "        decoded_cluster_centers = exp_results['decoded_labels']\n",
    "        decoded_cluster_labels = get_cluster_labels(decoded_cluster_centers, dataset, label_context_v1)\n",
    "        cluster_labels = []\n",
    "        for idx in range(len(decoded_cluster_labels)):\n",
    "            if len(decoded_cluster_labels[idx]) > 0:\n",
    "                cluster_labels.append(decoded_cluster_labels[idx])\n",
    "            else:\n",
    "                cluster_labels.append(direct_cluster_labels[idx])\n",
    "        df_cluster_merge = pd.DataFrame(np.array([[f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(direct_cluster_labels)],\n",
    "                                                  [f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(decoded_cluster_labels)],\n",
    "                                                  [f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(cluster_labels)]]).T,columns=['direct','decoded','combination_1'])\n",
    "        df_cluster_merge.to_csv(f\"{experiment_out_dir}/cluster_merge.csv\")\n",
    "        representation_acc = exp_results['repr_training_metrics'][-1]\n",
    "        json.dump(representation_acc, open(f\"{experiment_out_dir}/representation_accuracy.json\",\"w\"))\n",
    "\n",
    "    printm(\"### compile GT, Onto and Temporal results together\")\n",
    "    compiled_results_ts_dict  = compile_ts_results_v2(ts_results, df_gt_onto_pred,df_gt, cluster_labels)\n",
    "    # break\n",
    "    # get all available context from onto, gt and temporal\n",
    "    printm(\"### get all available contexts\")\n",
    "    if True:\n",
    "        all_context_list = []\n",
    "        for id in compiled_results_ts_dict.keys():\n",
    "            df_ts_id = compiled_results_ts_dict[id]\n",
    "            all_context_list += np.unique(df_ts_id['gt_context'].values).tolist()\n",
    "            all_context_list += np.unique(df_ts_id['pred_context'].values).tolist()\n",
    "            all_context_list += np.unique(df_ts_id['onto_context'].values).tolist()\n",
    "        all_context_list = np.unique(all_context_list).tolist()\n",
    "        all_context_list = [xr.split(\",\") for xr in all_context_list]\n",
    "        all_context_list = sorted(np.unique(np.concatenate(all_context_list)).tolist())\n",
    "        if '' in all_context_list:\n",
    "            del all_context_list[all_context_list.index('')]\n",
    "        if 'Unknown' in all_context_list:\n",
    "            del all_context_list[all_context_list.index('Unknown')]\n",
    "        json.dump(all_context_list, open(f\"{experiment_out_dir}/all_contexts.json\",\"w\"))\n",
    "\n",
    "    # Get metrics\n",
    "    printm(\"### get timestamp level metrics\")\n",
    "    if True:\n",
    "        metric_columns = ['gt_vec','onto_pred_vec','tp_pred_vec','combined_pred_vec']\n",
    "        for id_key in compiled_results_ts_dict.keys():\n",
    "            dft = compiled_results_ts_dict[id_key]\n",
    "            dft['gt_vec'] = dft.apply(lambda row: get_ctx_vec(row['gt_context'], all_context_list),axis=1)\n",
    "            dft['onto_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['onto_context'], all_context_list),axis=1)\n",
    "            dft['tp_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['pred_context'], all_context_list),axis=1)\n",
    "            dft['combined_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['combined_context'], all_context_list),axis=1)\n",
    "\n",
    "        ts_metrics = np.vstack([compiled_results_ts_dict[id][metric_columns].values for id in compiled_results_ts_dict.keys()])\n",
    "        df_ts_metrics = pd.DataFrame(ts_metrics,columns=metric_columns)\n",
    "        pickle.dump(compiled_results_ts_dict,open(f\"{experiment_out_dir}/compiled_results.pb\",\"wb\"))\n",
    "\n",
    "    # Get overall accuracy metrics for timestamps\n",
    "    printm(\"### get overall accuracy metrics\")\n",
    "    if True:\n",
    "        gt_ts_arr = np.stack(df_ts_metrics['gt_vec'].values)\n",
    "        onto_ts_arr = np.stack(df_ts_metrics['onto_pred_vec'].values)\n",
    "        tp_ts_arr = np.stack(df_ts_metrics['tp_pred_vec'].values)\n",
    "        combined_ts_arr = np.stack(df_ts_metrics['combined_pred_vec'].values)\n",
    "        onto_ts_metrics = get_overall_metrics(gt_ts_arr, onto_ts_arr)\n",
    "        tp_ts_metrics = get_overall_metrics(gt_ts_arr, tp_ts_arr)\n",
    "        combined_ts_metrics = get_overall_metrics(gt_ts_arr,combined_ts_arr)\n",
    "        df_overall_ts_metrics = pd.DataFrame([onto_ts_metrics,tp_ts_metrics,combined_ts_metrics],columns=['F1','PPV','TPR','JC'],index=['onto','temporal','combined'])\n",
    "        df_overall_ts_metrics.to_csv(f\"{experiment_out_dir}/overall_metrics.csv\")\n",
    "        print(df_overall_ts_metrics)\n",
    "    # context level accuracy\n",
    "    printm(\"### get context level accuracy metrics\")\n",
    "    if True:\n",
    "        df_context_ts_metrics = pd.DataFrame(all_context_list, columns=['context'])\n",
    "        df_context_ts_metrics['ppv_onto'] = precision_score(gt_ts_arr, onto_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_onto'] = recall_score(gt_ts_arr, onto_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['ppv_temporal'] = precision_score(gt_ts_arr, tp_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_temporal'] = recall_score(gt_ts_arr, tp_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['ppv_combined'] = precision_score(gt_ts_arr, combined_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_combined'] = recall_score(gt_ts_arr, combined_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics.to_csv(f\"{experiment_out_dir}/context_metrics.csv\")\n",
    "        print(df_context_ts_metrics)\n",
    "\n",
    "    printm(f\"## Finished Experiment {experiment}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_t = compiled_results_ts_dict['p4_3'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gt_context</th>\n",
       "      <th>pred_context</th>\n",
       "      <th>tao_prediction</th>\n",
       "      <th>combined_context</th>\n",
       "      <th>onto_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>Exercising,HavingMeal</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>Exercising,HavingMeal</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>Exercising,HavingMeal</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>Exercising,HavingMeal</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>Exercising</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>Exercising,HavingMeal</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>HavingMeal,OfficeWork</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>HavingMeal,OfficeWork</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>HavingMeal,OfficeWork</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>HavingMeal,OfficeWork</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>p4_3</td>\n",
       "      <td>1.662481e+09</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>OfficeWork</td>\n",
       "      <td>[HavingMeal]</td>\n",
       "      <td>HavingMeal,OfficeWork</td>\n",
       "      <td>HavingMeal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     timestamp  gt_context pred_context tao_prediction  \\\n",
       "0    p4_3  1.662481e+09  Exercising   Exercising   [HavingMeal]   \n",
       "1    p4_3  1.662481e+09  Exercising   Exercising   [HavingMeal]   \n",
       "2    p4_3  1.662481e+09  Exercising   Exercising   [HavingMeal]   \n",
       "3    p4_3  1.662481e+09  Exercising   Exercising   [HavingMeal]   \n",
       "4    p4_3  1.662481e+09  Exercising   Exercising   [HavingMeal]   \n",
       "..    ...           ...         ...          ...            ...   \n",
       "288  p4_3  1.662481e+09  OfficeWork   OfficeWork   [HavingMeal]   \n",
       "289  p4_3  1.662481e+09  OfficeWork   OfficeWork   [HavingMeal]   \n",
       "290  p4_3  1.662481e+09  OfficeWork   OfficeWork   [HavingMeal]   \n",
       "291  p4_3  1.662481e+09  OfficeWork   OfficeWork   [HavingMeal]   \n",
       "292  p4_3  1.662481e+09  OfficeWork   OfficeWork   [HavingMeal]   \n",
       "\n",
       "          combined_context onto_context  \n",
       "0    Exercising,HavingMeal   HavingMeal  \n",
       "1    Exercising,HavingMeal   HavingMeal  \n",
       "2    Exercising,HavingMeal   HavingMeal  \n",
       "3    Exercising,HavingMeal   HavingMeal  \n",
       "4    Exercising,HavingMeal   HavingMeal  \n",
       "..                     ...          ...  \n",
       "288  HavingMeal,OfficeWork   HavingMeal  \n",
       "289  HavingMeal,OfficeWork   HavingMeal  \n",
       "290  HavingMeal,OfficeWork   HavingMeal  \n",
       "291  HavingMeal,OfficeWork   HavingMeal  \n",
       "292  HavingMeal,OfficeWork   HavingMeal  \n",
       "\n",
       "[293 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Mites Accuracy numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id   timestamp           activity tao_prediction\n",
      "0  p10_1  1662667548            talking   [InAMeeting]\n",
      "1  p10_1  1662667549            talking   [InAMeeting]\n",
      "2  p10_1  1662667556            talking   [InAMeeting]\n",
      "3  p10_1  1662667557  doorknock,talking      [Unknown]\n",
      "4  p10_1  1662667558          doorknock     [ComingIn]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p1_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw_mites//p1_dataset_0.05_0.01_TAE/results/results_summary_20220913_201526.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p10_1\n",
      "Processed for id p10_1\n",
      "Starting on p10_2\n",
      "Processed for id p10_2\n",
      "Starting on p10_3\n",
      "Processed for id p10_3\n",
      "Starting on p10_4\n",
      "Processed for id p10_4\n",
      "Starting on p1_1\n",
      "Processed for id p1_1\n",
      "Starting on p1_2\n",
      "Processed for id p1_2\n",
      "Starting on p1_3\n",
      "Processed for id p1_3\n",
      "Starting on p1_4\n",
      "Processed for id p1_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      21.25  36.77  15.52  16.25\n",
      "temporal  28.32  28.05  29.85  20.16\n",
      "combined  32.54  33.65  34.22  21.99\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn     27.45     48.28         16.81         68.97   \n",
      "1       Exercising     36.54     22.89         19.35          7.23   \n",
      "2       HavingMeal     16.67      7.50         15.28         13.75   \n",
      "3        HouseWork     11.76      3.26          0.00          0.00   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork     55.19     21.79         55.22         56.92   \n",
      "7        PhoneCall     17.65      5.59          0.00          0.00   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing     64.62     24.28         45.41         51.45   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         16.30         75.86  \n",
      "1         32.84         26.51  \n",
      "2         15.28         13.75  \n",
      "3         11.76          3.26  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         55.69         60.26  \n",
      "7         17.65          5.59  \n",
      "8          0.00          0.00  \n",
      "9         46.77         54.34  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p1_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p3_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw_mites//p3_dataset_0.05_0.01_TAE/results/results_summary_20220913_203413.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p3_1\n",
      "Processed for id p3_1\n",
      "Starting on p3_2\n",
      "Processed for id p3_2\n",
      "Starting on p3_3\n",
      "Processed for id p3_3\n",
      "Starting on p3_4\n",
      "Processed for id p3_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      18.26  34.87  13.64  15.90\n",
      "temporal  30.79  45.54  32.31  25.28\n",
      "combined  31.99  37.74  33.44  25.10\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn     17.39     30.77         36.84         53.85   \n",
      "1       Exercising      8.33      6.06         10.77         21.21   \n",
      "2       HavingMeal     20.59     14.00         13.73         14.00   \n",
      "3        HouseWork     42.11      8.51        100.00          5.32   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork     54.21     27.62         58.94         73.81   \n",
      "7        PhoneCall     15.00      2.88         18.33         10.58   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing     50.00      3.28         46.67         11.48   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         21.21         53.85  \n",
      "1         10.45         21.21  \n",
      "2         13.73         14.00  \n",
      "3         52.17         12.77  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         58.49         73.81  \n",
      "7         18.33         10.58  \n",
      "8          0.00          0.00  \n",
      "9         46.67         11.48  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p3_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p10_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw_mites//p10_dataset_0.05_0.01_TAE/results/results_summary_20220913_201905.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p10_1\n",
      "Processed for id p10_1\n",
      "Starting on p10_2\n",
      "Processed for id p10_2\n",
      "Starting on p10_3\n",
      "Processed for id p10_3\n",
      "Starting on p10_4\n",
      "Processed for id p10_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      18.52  30.93  14.06  15.62\n",
      "temporal  20.83  21.61  23.65  15.17\n",
      "combined  24.51  25.01  27.98  16.85\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn     35.71     66.67          0.00          0.00   \n",
      "1       Exercising     41.67     26.79         23.44         26.79   \n",
      "2       HavingMeal     16.67     11.36         14.29         15.91   \n",
      "3        HouseWork      8.70      4.12          0.00          0.00   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork     41.67     16.43         35.38         21.60   \n",
      "7        PhoneCall     18.42      7.45         19.31         53.19   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing     57.69     17.44         31.25         40.70   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         35.71         66.67  \n",
      "1         30.67         41.07  \n",
      "2         14.00         15.91  \n",
      "3          8.70          4.12  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         37.41         24.41  \n",
      "7         19.31         53.19  \n",
      "8          0.00          0.00  \n",
      "9         31.25         40.70  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p10_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p5_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw_mites//p5_dataset_0.05_0.01_TAE/results/results_summary_20220913_203508.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p5_1\n",
      "Processed for id p5_1\n",
      "Starting on p5_2\n",
      "Processed for id p5_2\n",
      "Starting on p5_3\n",
      "Processed for id p5_3\n",
      "Starting on p5_4\n",
      "Processed for id p5_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      25.00  55.88  18.09  18.61\n",
      "temporal  31.36  50.99  32.80  19.47\n",
      "combined  32.58  46.42  34.39  19.74\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn      9.76     57.14          5.98        100.00   \n",
      "1       Exercising     61.54     18.60         56.41         51.16   \n",
      "2       HavingMeal     78.12     52.08         30.30         83.33   \n",
      "3        HouseWork     80.00      4.76        100.00          2.38   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork     52.83     16.47         45.16         32.94   \n",
      "7        PhoneCall     42.31     16.92         25.35         27.69   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing     55.00     18.97         68.97         34.48   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0          5.47        100.00  \n",
      "1         53.66         51.16  \n",
      "2         30.30         83.33  \n",
      "3         80.00          4.76  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         46.51         35.29  \n",
      "7         25.35         27.69  \n",
      "8          0.00          0.00  \n",
      "9         56.41         37.93  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p5_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p7_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw_mites//p7_dataset_0.05_0.01_TAE/results/results_summary_20220913_203932.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p7_1\n",
      "Processed for id p7_1\n",
      "Starting on p7_2\n",
      "Processed for id p7_2\n",
      "Starting on p7_3\n",
      "Processed for id p7_3\n",
      "Starting on p7_4\n",
      "Processed for id p7_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      25.86  39.69  20.81  23.02\n",
      "temporal  29.91  28.63  33.97  21.57\n",
      "combined  32.57  32.08  37.58  22.63\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn     26.32     41.67          6.49        100.00   \n",
      "1       Exercising     91.43     80.00         64.71         82.50   \n",
      "2       HavingMeal      0.00      0.00          3.33          3.85   \n",
      "3        HouseWork     14.29      2.56          0.00          0.00   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork     55.70     30.56         56.25         56.25   \n",
      "7        PhoneCall     24.00      7.50         13.11         10.00   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing     64.29     15.79         27.78         43.86   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0          6.45        100.00  \n",
      "1         68.97        100.00  \n",
      "2          3.33          3.85  \n",
      "3         14.29          2.56  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         58.00         60.42  \n",
      "7         13.11         10.00  \n",
      "8          0.00          0.00  \n",
      "9         29.35         47.37  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p7_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p2_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw_mites//p2_dataset_0.05_0.01_TAE/results/results_summary_20220913_203346.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p2_1\n",
      "Processed for id p2_1\n",
      "Starting on p2_2\n",
      "Processed for id p2_2\n",
      "Starting on p2_3\n",
      "Processed for id p2_3\n",
      "Starting on p2_4\n",
      "Processed for id p2_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      13.22  44.05   8.49  10.40\n",
      "temporal  28.42  25.84  33.08  17.42\n",
      "combined  28.74  25.94  33.96  16.78\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn     19.05     20.00         13.16         50.00   \n",
      "1       Exercising     10.34      8.11          0.00          0.00   \n",
      "2       HavingMeal      0.00      0.00          7.08         10.39   \n",
      "3        HouseWork      3.85      0.91         12.70         14.55   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork     69.33     18.64         50.32         56.63   \n",
      "7        PhoneCall     25.00      2.46         17.74         18.03   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00      4.27         19.54         43.59   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         12.90         60.00  \n",
      "1          4.00          8.11  \n",
      "2          7.08         10.39  \n",
      "3         11.51         14.55  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         50.63         57.35  \n",
      "7         17.60         18.03  \n",
      "8          0.00          0.00  \n",
      "9         19.54         43.59  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p2_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p4_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw_mites//p4_dataset_0.05_0.01_TAE/results/results_summary_20220913_203419.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p4_1\n",
      "Processed for id p4_1\n",
      "Starting on p4_2\n",
      "Processed for id p4_2\n",
      "Starting on p4_3\n",
      "Processed for id p4_3\n",
      "Starting on p4_4\n",
      "Processed for id p4_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      12.07  45.46   9.14  10.65\n",
      "temporal  31.62  33.80  32.49  19.57\n",
      "combined  32.38  35.45  33.50  19.42\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn     14.71     55.56          8.74        100.00   \n",
      "1       Exercising     21.82     37.50         22.22         68.75   \n",
      "2       HavingMeal      0.00      0.00          1.69          2.08   \n",
      "3        HouseWork     11.11      2.38          0.00          0.00   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork     64.71     10.05         61.75         51.60   \n",
      "7        PhoneCall     33.33     15.07         27.63         28.77   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing    100.00      2.35         41.94         30.59   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0          8.18        100.00  \n",
      "1         23.15         78.12  \n",
      "2          1.69          2.08  \n",
      "3         11.11          2.38  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         61.96         52.05  \n",
      "7         27.27         28.77  \n",
      "8          0.00          0.00  \n",
      "9         41.94         30.59  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p4_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## --------------------------- Started Experiment: p6_dataset_0.05_0.01_TAE ----------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### fetch results for experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../cache/sep12_rw_mites//p6_dataset_0.05_0.01_TAE/results/results_summary_20220913_203859.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get cluster labels and best representation accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### compile GT, Onto and Temporal results together"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on p6_1\n",
      "Processed for id p6_1\n",
      "Starting on p6_2\n",
      "Processed for id p6_2\n",
      "Starting on p6_3\n",
      "Processed for id p6_3\n",
      "Starting on p6_4\n",
      "Processed for id p6_4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get all available contexts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get timestamp level metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### get overall accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             F1    PPV    TPR     JC\n",
      "onto      25.10  40.52  20.35  23.25\n",
      "temporal  38.15  34.40  46.10  34.48\n",
      "combined  37.89  33.76  46.32  33.28\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### get context level accuracy metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           context  ppv_onto  tpr_onto  ppv_temporal  tpr_temporal  \\\n",
      "0         ComingIn     15.15     38.46         16.88        100.00   \n",
      "1       Exercising     33.33     14.29         41.67         23.81   \n",
      "2       HavingMeal     22.86     25.00         26.79         46.88   \n",
      "3        HouseWork      0.00      0.00          0.00          0.00   \n",
      "4       InAMeeting      0.00      0.00          0.00          0.00   \n",
      "5  MealPreparation      0.00      0.00          0.00          0.00   \n",
      "6       OfficeWork     54.00     31.03         56.28         69.54   \n",
      "7        PhoneCall     36.59     25.00         15.00         30.00   \n",
      "8    PreparingMeal      0.00      0.00          0.00          0.00   \n",
      "9         Relaxing     85.71     10.71         42.35         64.29   \n",
      "\n",
      "   ppv_combined  tpr_combined  \n",
      "0         15.66        100.00  \n",
      "1         38.46         23.81  \n",
      "2         25.42         46.88  \n",
      "3          0.00          0.00  \n",
      "4          0.00          0.00  \n",
      "5          0.00          0.00  \n",
      "6         55.71         70.11  \n",
      "7         15.00         30.00  \n",
      "8          0.00          0.00  \n",
      "9         42.35         64.29  \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Finished Experiment p6_dataset_0.05_0.01_TAE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mites_cache_dir = \"../../cache/sep12_rw_mites/\"\n",
    "experiment_dirs = glob.glob(f'{mites_cache_dir}/*')\n",
    "df_mites_onto_pred = pd.read_csv(\"../../ontological_models/real_world_mites_ontology_predictions.csv\")\n",
    "# df_mites_onto_pred['tao_prediction'] = df_mites_onto_pred['tao_prediction'].apply(lambda x: x.replace('noevent','Unknown'))\n",
    "df_mites_onto_pred['tao_prediction'] = df_mites_onto_pred['tao_prediction'].apply(\n",
    "    lambda x: x.split(\";\") if not (str(x) == 'nan') else ['Unknown'])\n",
    "df_mites_onto_pred['tao_prediction'] = df_mites_onto_pred['tao_prediction'].apply(\n",
    "    lambda x: ['Unknown'] if (x[0]=='noevent') else x)\n",
    "df_mites_onto_pred = df_mites_onto_pred.rename(columns={'session_id':'id'})\n",
    "print(df_mites_onto_pred.head())\n",
    "\n",
    "df_metrics =None\n",
    "for experiment_dir in experiment_dirs:\n",
    "    experiment = experiment_dir.split(\"/\")[-1]\n",
    "    experiment_out_dir = f'{out_result_dir}/mites_{experiment}'\n",
    "    if not os.path.exists(experiment_out_dir):\n",
    "        os.makedirs(experiment_out_dir)\n",
    "\n",
    "    printm(f\"## --------------------------- Started Experiment: {experiment} ----------------------------\")\n",
    "    # Compile results into ts dict\n",
    "    printm(\"### fetch results for experiment\")\n",
    "    if True:\n",
    "        result_file = sorted(glob.glob(f\"{mites_cache_dir}/{experiment}/results/{result_summary_prefix}*.json\"))[-1]\n",
    "        ts_file = sorted(glob.glob(f\"{mites_cache_dir}/{experiment}/results/{ts_prediction_file_prefix}*.pb\"))[-1]\n",
    "        print(result_file)\n",
    "        exp_results = json.load(open(result_file, 'r'))\n",
    "        ts_results = pickle.load(open(ts_file, 'rb'))\n",
    "        cluster_centers = exp_results['direct_labels']\n",
    "        dataset = exp_results['run_config']['dataset']\n",
    "\n",
    "    # Filter out only test instances from ts_results\n",
    "    zero_shape_ids = []\n",
    "    for id in ts_results.keys():\n",
    "        # print(f\"id:{id}:{ts_results[id].shape}\")\n",
    "        ts_results[id] = ts_results[id][ts_results[id].isTrain==False]\n",
    "        # print(f\"id:{id}:{ts_results[id].shape}\")\n",
    "        if ts_results[id].shape[0]==0:\n",
    "            zero_shape_ids.append(id)\n",
    "    for id in zero_shape_ids:\n",
    "        del ts_results[id]\n",
    "\n",
    "\n",
    "    printm(\"### get cluster labels and best representation accuracy\")\n",
    "    if True:\n",
    "        direct_cluster_centers = exp_results['direct_labels']\n",
    "        direct_cluster_labels = get_cluster_labels(direct_cluster_centers, dataset, label_context_v1)\n",
    "        decoded_cluster_centers = exp_results['decoded_labels']\n",
    "        decoded_cluster_labels = get_cluster_labels(decoded_cluster_centers, dataset, label_context_v1)\n",
    "        cluster_labels = []\n",
    "        for idx in range(len(decoded_cluster_labels)):\n",
    "            if len(decoded_cluster_labels[idx]) > 0:\n",
    "                cluster_labels.append(decoded_cluster_labels[idx])\n",
    "            else:\n",
    "                cluster_labels.append(direct_cluster_labels[idx])\n",
    "        df_cluster_merge = pd.DataFrame(np.array([[f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(direct_cluster_labels)],\n",
    "                                                  [f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(decoded_cluster_labels)],\n",
    "                                                  [f\"{idx}:\"+','.join(cr) for idx,cr in enumerate(cluster_labels)]]).T,columns=['direct','decoded','combination_1'])\n",
    "        df_cluster_merge.to_csv(f\"{experiment_out_dir}/cluster_merge.csv\")\n",
    "        representation_acc = exp_results['repr_training_metrics'][-1]\n",
    "        json.dump(representation_acc, open(f\"{experiment_out_dir}/representation_accuracy.json\",\"w\"))\n",
    "\n",
    "    printm(\"### compile GT, Onto and Temporal results together\")\n",
    "    compiled_results_ts_dict  = compile_ts_results_v2(ts_results, df_mites_onto_pred,df_gt, cluster_labels)\n",
    "    # break\n",
    "    # get all available context from onto, gt and temporal\n",
    "    printm(\"### get all available contexts\")\n",
    "    if True:\n",
    "        all_context_list = []\n",
    "        for id in compiled_results_ts_dict.keys():\n",
    "            df_ts_id = compiled_results_ts_dict[id]\n",
    "            all_context_list += np.unique(df_ts_id['gt_context'].values).tolist()\n",
    "            all_context_list += np.unique(df_ts_id['pred_context'].values).tolist()\n",
    "            all_context_list += np.unique(df_ts_id['onto_context'].values).tolist()\n",
    "        all_context_list = np.unique(all_context_list).tolist()\n",
    "        all_context_list = [xr.split(\",\") for xr in all_context_list]\n",
    "        all_context_list = sorted(np.unique(np.concatenate(all_context_list)).tolist())\n",
    "        if '' in all_context_list:\n",
    "            del all_context_list[all_context_list.index('')]\n",
    "        if 'Unknown' in all_context_list:\n",
    "            del all_context_list[all_context_list.index('Unknown')]\n",
    "        json.dump(all_context_list, open(f\"{experiment_out_dir}/all_contexts.json\",\"w\"))\n",
    "\n",
    "    # Get metrics\n",
    "    printm(\"### get timestamp level metrics\")\n",
    "    if True:\n",
    "        metric_columns = ['gt_vec','onto_pred_vec','tp_pred_vec','combined_pred_vec']\n",
    "        for id_key in compiled_results_ts_dict.keys():\n",
    "            dft = compiled_results_ts_dict[id_key]\n",
    "            dft['gt_vec'] = dft.apply(lambda row: get_ctx_vec(row['gt_context'], all_context_list),axis=1)\n",
    "            dft['onto_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['onto_context'], all_context_list),axis=1)\n",
    "            dft['tp_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['pred_context'], all_context_list),axis=1)\n",
    "            dft['combined_pred_vec'] = dft.apply(lambda row: get_ctx_vec(row['combined_context'], all_context_list),axis=1)\n",
    "\n",
    "        ts_metrics = np.vstack([compiled_results_ts_dict[id][metric_columns].values for id in compiled_results_ts_dict.keys()])\n",
    "        df_ts_metrics = pd.DataFrame(ts_metrics,columns=metric_columns)\n",
    "        pickle.dump(compiled_results_ts_dict,open(f\"{experiment_out_dir}/compiled_results.pb\",\"wb\"))\n",
    "\n",
    "    # Get overall accuracy metrics for timestamps\n",
    "    printm(\"### get overall accuracy metrics\")\n",
    "    if True:\n",
    "        gt_ts_arr = np.stack(df_ts_metrics['gt_vec'].values)\n",
    "        onto_ts_arr = np.stack(df_ts_metrics['onto_pred_vec'].values)\n",
    "        tp_ts_arr = np.stack(df_ts_metrics['tp_pred_vec'].values)\n",
    "        combined_ts_arr = np.stack(df_ts_metrics['combined_pred_vec'].values)\n",
    "        onto_ts_metrics = get_overall_metrics(gt_ts_arr, onto_ts_arr)\n",
    "        tp_ts_metrics = get_overall_metrics(gt_ts_arr, tp_ts_arr)\n",
    "        combined_ts_metrics = get_overall_metrics(gt_ts_arr,combined_ts_arr)\n",
    "        df_overall_ts_metrics = pd.DataFrame([onto_ts_metrics,tp_ts_metrics,combined_ts_metrics],columns=['F1','PPV','TPR','JC'],index=['onto','temporal','combined'])\n",
    "        df_overall_ts_metrics.to_csv(f\"{experiment_out_dir}/overall_metrics.csv\")\n",
    "        print(df_overall_ts_metrics)\n",
    "    # context level accuracy\n",
    "    printm(\"### get context level accuracy metrics\")\n",
    "    if True:\n",
    "        df_context_ts_metrics = pd.DataFrame(all_context_list, columns=['context'])\n",
    "        df_context_ts_metrics['ppv_onto'] = precision_score(gt_ts_arr, onto_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_onto'] = recall_score(gt_ts_arr, onto_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['ppv_temporal'] = precision_score(gt_ts_arr, tp_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_temporal'] = recall_score(gt_ts_arr, tp_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['ppv_combined'] = precision_score(gt_ts_arr, combined_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics['tpr_combined'] = recall_score(gt_ts_arr, combined_ts_arr, average=None,zero_division=0).round(4)*100\n",
    "        df_context_ts_metrics.to_csv(f\"{experiment_out_dir}/context_metrics.csv\")\n",
    "        print(df_context_ts_metrics)\n",
    "\n",
    "    printm(f\"## Finished Experiment {experiment}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context_sensing_2",
   "language": "python",
   "name": "context_sensing_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
